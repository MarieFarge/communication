\documentclass[a4paper,11pt]{article}

\input{prelude}

\title{How general are categorical models of meaning?}
\date{\today}

\begin{document}

\maketitle

\section{Introduction}

The distributional compositional model of meaning of \cite{clark2008compositional}
is motivated by category theory, and has hence many elegant properties. In practice
however, implementations often depart from the original framework: after all, if
stacking two vectors yields better results than taking their outer product, why should
we bother abiding by this mathematical orthodoxy? 

In this poster, we argue that we can get both the theoretical guarantees
of category theory and the flexibility of alternate models of meaning using
the notion of \emph{free compact closed category}.
This notion can be used to recast alternate models of meaning, such as neural networks
for instance, in the type-driven framework.
This observation calls for a generic tool easing the implementation of categorical
models of meaning, a linguistic counterpart to the Quantomatic software used
in quantum physics.


\section{The traditional model: linear maps and the tensor product}

The most popular semantic category for distributional models is the
autonomous category of finite-dimensional vector spaces and linear maps
between them, denoted by $\Vect$, with the tensor product $\otimes$ as
monoidal operation.  This
tradition has been initiated in the early works of
\cite{clark2007combining,clark2008compositional,coecke2010mathematical}.

The main problem with this category is that the dimensions of the vector
spaces associated with complex syntactic types are prohibitively large.
Dimensionality reduction techniques have been devised, but the nature of
the category restricts the range of possible algebraic operations. For
instance, a very useful baseline for the composition of word vectors
consists in taking the sum of the vectors for each word in the sentence.
This baseline cannot be recast in $\Vect$
because $u + v$ is not a linear function of $u \otimes v$.

Another argument against linearity is that it can ignore some form
of structure in the vectors, such as the famous $\vec{King} - \vec{Man}
+ \vec{Woman} \simeq \vec{Queen}$ of \cite{mikolov2013efficient}. When this
kind of relation holds, one might want to represent adjectives such as \emph{female}
by functions adding a vector to their argument, but it is
impossible if our arrows are simply linear maps: we would need affine maps.

\section{Alternate models of meaning}

Replacing the tensor product by the direct sum $\oplus$ solves
the problems mentionned above: $u + v$ is a linear function of $(u,v)$.
Moreover, the dimension of $U \otimes V$ is $\dim U + \dim V$,
which solves the dimensionality issues of tensors.

However, there is no equivalent of tensor contraction (also called the counit)
for the direct sum.
This is where free compact closed categories become useful: we can embed
our candidate model of meaning in a larger category where units and counits exist.

We can go further by allowing
nonlinearities, which leads us to neural models of meaning. 
Neural networks are functions obtained by the composition of linear maps
and a special non-linear function called the activation function.  We
fix such a function $\sigma : \mathbb{R} \to \mathbb{R}$. It is
generally required to be continuous, non-constant and bounded.  The
\emph{neuron} is the basic block of these networks: it applies the
nonlinear function to an affine combination of its inputs: $p :
\mathbb{R}^n \to \mathbb{R} \coloneqq \sigma \circ f$ where $f$ is
affine and $\sigma$ is the activation function.  How this basic block
can be combined to make more complex networks is conveniently described
by a monoidal category.

The following figure compares the
classical representation of a neural network to its string diagram in
$\Net$.

\begin{figure}[H]
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
    \input{figures/normalform} %\vspace{0.1cm}
    \caption{An arrow in $\Net_\sigma$. \\ $f$ and $g$ are affine maps.}
    \label{fig:normalform}
  \end{subfigure}
  \begin{subfigure}[b]{0.45\textwidth}
    \input{figures/neuralnet}
    \caption{Its traditional representation as a neural network}
    \label{fig:neuralnet}
  \end{subfigure}
\end{figure}



\bibliographystyle{chicago}
\bibliography{references}

\end{document}

